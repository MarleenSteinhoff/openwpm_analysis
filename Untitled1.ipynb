{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9574e0b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# packages changed for python 3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# pip install adblockparser\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manalyze_crawl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_crawl_db_path, get_crawl_dir\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n",
      "File \u001b[0;32m~/UNi/Projektseminar/Datenanalyse/analysis/analyze_crawl.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcrawl_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdomain_utils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdu\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_visit_id_site_url_mapping\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# packages changed for python 3\n",
    "# pip install adblockparser\n",
    "\n",
    "import sys\n",
    "from analyze_crawl import get_crawl_db_path, get_crawl_dir\n",
    "import ast\n",
    "import sqlite3\n",
    "from pqdm.processes import pqdm\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from urllib.parse import urlparse\n",
    "from os.path import realpath, join, basename, sep\n",
    "from _collections import defaultdict\n",
    "\n",
    "# https://github.com/scrapinghub/adblockparser\n",
    "from adblockparser import AdblockRules\n",
    "from util import dump_as_json, get_visit_id_http_status_mapping, get_successfull_crawled_ids, \\\n",
    "    get_visit_id_site_url_mapping\n",
    "from analysis_utils.utils import (is_third_party, is_blocked_by_disconnect,\n",
    "                                  get_disconnect_blocked_hosts, get_delta_timespan)\n",
    "\n",
    "OUTDIR = \"\"\n",
    "CRAWL_NAME = \"\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8948d26b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# packages changed for python 3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# pip install adblockparser\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manalyze_crawl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_crawl_db_path, get_crawl_dir\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n",
      "File \u001b[0;32m~/UNi/Projektseminar/Datenanalyse/analysis/analyze_crawl.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcrawl_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdomain_utils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdu\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_visit_id_site_url_mapping\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# search for the occurences of ublock after enabling this switch\n",
    "ENABLE_UBLOCK = False\n",
    "# Only lookup scripts with sensor access\n",
    "CHECK_ADBLOCK_STATUS_OF_ALL_JS = True  # False means we only check\n",
    "# scripts with sensor access\n",
    "DB = ''\n",
    "NO_RANK = []\n",
    "CONTAINS_NONE_RANKS = []\n",
    "DB_NAME = ''\n",
    "RESULTS_PATH = \"/home/marleensteinhoff/UNi/Projektseminar/Datenanalyse/analysis/data/results\"\n",
    "# standard JavaScript, DOM events\n",
    "JS_EVENTS = \\\n",
    "    [\"DOMContentLoaded\", \"DOMMouseScroll\", \"abort\", \"afterprint\",\n",
    "     \"animationend\", \"animationiteration\", \"animationstart\",\n",
    "     \"appinstalled\", \"auxclick\", \"beforeinstallprompt\",\n",
    "     \"beforeprint\", \"beforescriptexecute\", \"beforeunload\",\n",
    "     \"blur\", \"canplay\", \"canplaythrough\", \"change\",\n",
    "     \"chargingchange\", \"chargingtimechange\", \"click\",\n",
    "     \"compassneedscalibration\", \"complete\", \"contextmenu\",\n",
    "     \"copy\", \"cut\", \"dblclick\", \"devicechange\", \"devicelight\",\n",
    "     \"devicemotion\", \"deviceorientation\", \"deviceproximity\",\n",
    "     \"dischargingtimechange\", \"drag\", \"dragend\", \"dragenter\",\n",
    "     \"dragleave\", \"dragover\", \"dragstart\", \"drop\", \"durationchange\",\n",
    "     \"emptied\", \"ended\", \"error\", \"focus\", \"focusin\", \"focusout\",\n",
    "     \"fullscreenchange\", \"gamepadconnected\", \"hashchange\", \"input\",\n",
    "     \"invalid\", \"keydown\", \"keypress\", \"keyup\", \"levelchange\",\n",
    "     \"load\", \"loadeddata\", \"loadedmetadata\", \"loadstart\", \"localized\",\n",
    "     \"message\", \"mousedown\", \"mouseenter\", \"mouseleave\", \"mousemove\",\n",
    "     \"mouseout\", \"mouseover\", \"mouseup\", \"notificationclick\",\n",
    "     \"offline\", \"online\", \"orientationchange\", \"overflow\", \"pagehide\",\n",
    "     \"pageshow\", \"paste\", \"pause\", \"play\", \"playing\", \"pointercancel\",\n",
    "     \"pointerdown\", \"pointerleave\", \"pointermove\", \"pointerover\",\n",
    "     \"pointerup\", \"popstate\", \"progress\", \"push\", \"ratechange\",\n",
    "     \"readystatechange\", \"reset\", \"resize\", \"scroll\", \"seeked\",\n",
    "     \"seeking\", \"select\", \"show\", \"stalled\", \"start\", \"statechange\",\n",
    "     \"storage\", \"submit\", \"suspend\", \"timeupdate\", \"touchcancel\",\n",
    "     \"touchend\", \"touchenter\", \"touchleave\", \"touchmove\", \"touchstart\",\n",
    "     \"transitionend\", \"transitionstart\", \"unload\", \"userproximity\",\n",
    "     \"visibilitychange\", \"volumechange\", \"vrdisplayactivate\",\n",
    "     \"vrdisplaydeactivate\", \"vrdisplaypresentchange\", \"waiting\", \"wheel\"]\n",
    "\n",
    "\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def get_event_feature(arguments, symbol):\n",
    "    arguments_obj = json.loads(arguments)\n",
    "    event_name = arguments_obj[\"0\"]\n",
    "    if event_name in JS_EVENTS:\n",
    "        return \"addEventListener_\" + event_name\n",
    "    else:  # custom event\n",
    "        if DEBUG and event_name != \"test\":\n",
    "            print(\"Custom Event:\", event_name)\n",
    "        return \"addEventListener_CUSTOM_EVENT\"\n",
    "\n",
    "\n",
    "def get_simple_feature_from_js_info(operation, arguments, symbol):\n",
    "    if symbol.endswith(\"addEventListener\") and operation == \"call\":\n",
    "        return get_event_feature(arguments, symbol)\n",
    "    elif operation == \"call\":\n",
    "        return \"call_\" + symbol\n",
    "    elif operation == \"get\":\n",
    "        return \"get_\" + symbol\n",
    "    elif operation == \"set\":\n",
    "        return \"set_\" + symbol\n",
    "\n",
    "\n",
    "CANVAS_READ_FUNCS = [\n",
    "    \"HTMLCanvasElement.toDataURL\",\n",
    "    \"CanvasRenderingContext2D.getImageData\"\n",
    "]\n",
    "\n",
    "CANVAS_WRITE_FUNCS = [\n",
    "    \"CanvasRenderingContext2D.fillText\",\n",
    "    \"CanvasRenderingContext2D.strokeText\"\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Criteria 3 from Englehardt & Narayanan, 2016\n",
    "\"3. The script should not call the save, restore, or addEventListener\n",
    "methods of the rendering context.\"\n",
    "`addEventListener` is (can) only called for HTMLCanvasElement, so we use that.\n",
    "\"\"\"\n",
    "CANVAS_FP_DO_NOT_CALL_LIST = [\"CanvasRenderingContext2D.save\",\n",
    "                              \"CanvasRenderingContext2D.restore\",\n",
    "                              \"HTMLCanvasElement.addEventListener\"]\n",
    "AUDIO_CONTEXT_FUNCS = [\n",
    "    \"OfflineAudioContext.createOscillator\",\n",
    "    \"OfflineAudioContext.createDynamicsCompressor\",\n",
    "    \"OfflineAudioContext.destination\",\n",
    "    \"OfflineAudioContext.startRendering\",\n",
    "    \"OfflineAudioContext.oncomplete\"\n",
    "]\n",
    "\n",
    "WEBRTC_FP_CALLS = [\"RTCPeerConnection.createDataChannel\",\n",
    "                   \"RTCPeerConnection.createOffer\"]\n",
    "\n",
    "# Functions to get the charging time\n",
    "BATTERY_CHARGING_TIME_CALLS = [\"BatteryManager.chargingTime\",\n",
    "                               \"BatteryManager.onchargingtimechange\"]\n",
    "\n",
    "# Functions to get the discharging time\n",
    "BATTERY_DISCHARGING_TIME_CALLS = [\"BatteryManager.dischargingTime\",\n",
    "                                  \"BatteryManager.ondischargingtimechange\"]\n",
    "# cookie features\n",
    "NUM_COOKIE_SETTERS = \"num_cookie_setters\"\n",
    "NUM_COOKIE_TOTAL = \"num_cookie_total\"\n",
    "NUM_SESSION_COOKIES = \"num_session_cookies\"\n",
    "NUM_TRACKING_COOKIES = \"num_tracking_cookies\"\n",
    "NUM_HTTP_COOKIES = \"num_http_cookies\"\n",
    "NUM_VERY_LONG_COOKIE = \"num_very_long_cookie\"\n",
    "NUM_LONG_COOKIE = \"num_long_cookie\"\n",
    "NUM_CRAWLED_URLS = \"num_crawled_urls\"\n",
    "COOKIE_SETTERS = \"cookie_setters\"\n",
    "\n",
    "PER_JS_COOKIES = \"per_js_cookies\"\n",
    "PER_COOKIE_TOTAL = \"per_cookie_total\"\n",
    "PER_SESSION_COOKIES = \"per_session_cookies\"\n",
    "PER_TRACKING_COOKIES = \"per_tracking_cookies\"\n",
    "PER_HTTP_COOKIES = \"per_http_cookies\"\n",
    "PER_HTTP_ONLY = \"per_http_only\"\n",
    "PER_VERY_LONG_COOKIE = \"per_very_long_cookie\"\n",
    "PER_LONG_COOKIE = \"per_long_cookie\"\n",
    "\n",
    "TRACKING_SITE_URLS = \"tracking_site_urls\"\n",
    "SITEURL_COOKIE_MAPPING = \"siteurl_cookie_mapping\"\n",
    "\n",
    "# count high level features\n",
    "NUM_CANVAS_FP = \"num_canvas_fingerprinting\"\n",
    "NUM_CANVAS_FONT_FP = \"num_canvas_font_fingerprinting\"\n",
    "NUM_AUDIO_CTX_FP = \"num_audio_context_fingerprinting\"\n",
    "NUM_WEBRTC_FP = \"num_webrtc_fingerprinting\"\n",
    "NUM_BATTERY_FP = \"num_battery_fingerprinting\"\n",
    "NUM_TRIGGERS_REQUEST = \"num_triggers_requests\"\n",
    "NUM_TRIGGERS_TP_REQUEST = \"num_triggers_third_party_requests\"\n",
    "NUM_EASYLIST_BLOCKED = \"num_easylist_blocked\"\n",
    "NUM_EASYPRIVACY_BLOCKED = \"num_easyprivacy_blocked\"\n",
    "# NUM_UBLOCK_ORIGIN_BLOCKED = \"num_ublockorigin_blocked\"\n",
    "NUM_DISCONNECT_BLOCKED = \"num_disconnect_blocked\"\n",
    "NUM_THIRD_PARTY_SCRIPT = \"num_third_party_script\"\n",
    "\n",
    "COUNT_FEATURES = [NUM_CANVAS_FP, NUM_CANVAS_FONT_FP, NUM_AUDIO_CTX_FP,\n",
    "                  NUM_WEBRTC_FP, NUM_BATTERY_FP,\n",
    "                  NUM_TRIGGERS_REQUEST, NUM_TRIGGERS_TP_REQUEST,\n",
    "                  NUM_EASYLIST_BLOCKED, NUM_EASYPRIVACY_BLOCKED,\n",
    "                  # UBLOCK_ORIGIN_BLOCKED,\n",
    "                  NUM_DISCONNECT_BLOCKED,\n",
    "                  NUM_THIRD_PARTY_SCRIPT]\n",
    "# Cookie features\n",
    "FB_COOKIEMONSTER_BLOCKED = \"cookiemonster_blocked\"\n",
    "JS_COOKIES = \"javascript_cookies\"\n",
    "TRACKING_COOKIES = \"tracking_cookies\"\n",
    "HTTP_COOKIES = \"http_cookies\"\n",
    "THRD_PARTY_COOKIES = \"third_party_cookies\"\n",
    "\n",
    "# High level features\n",
    "CANVAS_FP = \"canvas_fingerprinting\"\n",
    "CANVAS_FONT_FP = \"canvas_font_fingerprinting\"\n",
    "AUDIO_CTX_FP = \"audio_context_fingerprinting\"\n",
    "WEBRTC_FP = \"webrtc_fingerprinting\"\n",
    "BATTERY_FP = \"battery_fingerprinting\"\n",
    "TRIGGERS_REQUEST = \"triggers_requests\"\n",
    "TRIGGERS_TP_REQUEST = \"triggers_third_party_requests\"\n",
    "EASYLIST_BLOCKED = \"easylist_blocked\"\n",
    "EASYPRIVACY_BLOCKED = \"easyprivacy_blocked\"\n",
    "UBLOCK_ORIGIN_BLOCKED = \"ublockorigin_blocked\"\n",
    "DISCONNECT_BLOCKED = \"disconnect_blocked\"\n",
    "THIRD_PARTY_SCRIPT = \"third_party_script\"\n",
    "\n",
    "HIGH_LEVEL_FEATURES = [CANVAS_FP, CANVAS_FONT_FP, AUDIO_CTX_FP,\n",
    "                       WEBRTC_FP, BATTERY_FP,\n",
    "                       TRIGGERS_REQUEST, TRIGGERS_TP_REQUEST,\n",
    "                       EASYLIST_BLOCKED, EASYPRIVACY_BLOCKED,\n",
    "                       # UBLOCK_ORIGIN_BLOCKED,\n",
    "                       DISCONNECT_BLOCKED,\n",
    "                       THIRD_PARTY_SCRIPT]\n",
    "\n",
    "MIN_CANVAS_TEXT_LEN = 10\n",
    "MIN_CANVAS_IMAGE_WIDTH = 16\n",
    "MIN_CANVAS_IMAGE_HEIGHT = 16\n",
    "\n",
    "\n",
    "def get_canvas_text(arguments):\n",
    "    if not arguments:\n",
    "        return \"\"\n",
    "    canvas_write_args = json.loads(arguments)\n",
    "    try:\n",
    "        # cast numbers etc. to string\n",
    "        return str(canvas_write_args[\"0\"])\n",
    "    except Exception:\n",
    "        try:\n",
    "            # for non-ascii strings\n",
    "            return str(canvas_write_args[\"0\"].encode(\"utf-8\"))\n",
    "        except Exception:\n",
    "            # if we cannot decode a call's arguments we exclude it\n",
    "            # from the analysis to prevent false positives\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "def safe_int(string):\n",
    "    \"\"\"Convert string to int, return 0 if conversion fails.\"\"\"\n",
    "    try:\n",
    "        return int(string)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_get_image_data_dimensions_too_small(arguments):\n",
    "    \"\"\"Check if the retrieved canvas data is greater than min dimensions.\"\"\"\n",
    "    # https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData#Parameters  # noqa\n",
    "    get_image_data_args = json.loads(arguments)\n",
    "    sw = safe_int(get_image_data_args.get(\"2\", 0))\n",
    "    sh = safe_int(get_image_data_args.get(\"3\", 0))\n",
    "    MIN_CANVAS_IMAGE_WIDTH = 16\n",
    "    return (sw < MIN_CANVAS_IMAGE_WIDTH) or (sh < MIN_CANVAS_IMAGE_HEIGHT)\n",
    "\n",
    "\n",
    "def get_base_script_url(script_url):\n",
    "    return script_url.split(\"//\")[1].split(\"/\")[0]\n",
    "\n",
    "\n",
    "def get_script_freqs_from_db(db_file, max_rank=None):\n",
    "    \"\"\"Return a frequency count for each script.\"\"\"\n",
    "    connection = sqlite3.connect(db_file)\n",
    "    c = connection.cursor()\n",
    "\n",
    "    query = \"\"\"SELECT visit_id, script_url FROM javascript WHERE\n",
    "        script_url <> ''\n",
    "        \"\"\"\n",
    "    if max_rank is not None:\n",
    "        query += \" AND visit_id <= %i\" % max_rank\n",
    "\n",
    "    overall_script_ranks = defaultdict(set)\n",
    "    for row in c.execute(query):\n",
    "        visit_id, script_url = row[0:2]\n",
    "        # Exclude scripts with visit_id = -1\n",
    "        # This happens when OpenWPM doesn't know which visit a script belong to\n",
    "        if visit_id == -1:\n",
    "            continue\n",
    "        # Exclude relative URLs, data urls, blobs\n",
    "        if not (script_url.startswith(\"http://\")\n",
    "                or script_url.startswith(\"https://\")):\n",
    "            continue\n",
    "        script_adress = get_base_script_url(script_url)\n",
    "        overall_script_ranks[script_adress].add(visit_id)\n",
    "    return overall_script_ranks\n",
    "\n",
    "\n",
    "# This list is only used to decide if\n",
    "# we want to check adblock status of scripts.\n",
    "# We'll probably won'tuse userprosimity\n",
    "# but let's save the adblocked status of the scripts accessing userproximity\n",
    "SENSOR_FEATURES = [\n",
    "    \"addEventListener_devicelight\",\n",
    "    \"addEventListener_deviceorientation\",\n",
    "    \"addEventListener_deviceproximity\",\n",
    "    \"addEventListener_devicemotion\"\n",
    "    # ,\"addEventListener_userproximity\"\n",
    "]\n",
    "\"\"\"\n",
    "    #query = \"SELECT * FROM javascript_cookies\"\n",
    "    js_cookies = pd.read_sql_query(query, connection)\n",
    "    b = js_cookies.loc[js_cookies[\"is_session\"] == 1]\n",
    "    d = js_cookies.size\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "def get_cookies(db_file, id_urls_map=defaultdict(), max_rank=None):\n",
    "    print(\"get_cookies\")\n",
    "    # database conn\n",
    "    db = sqlite3.connect(db_file)\n",
    "    db.row_factory = sqlite3.Row\n",
    "    c = db.cursor()\n",
    "\n",
    "    num_cookie_total = 0\n",
    "    num_session_cookies = 0\n",
    "    num_tracking_cookies = 0\n",
    "    num_http_cookies = 0\n",
    "    num_very_long_cookie = 0\n",
    "    num_long_cookie = 0\n",
    "    num_crawled_urls = len(get_successfull_crawled_ids(db))\n",
    "    tracking_site_urls = defaultdict()\n",
    "    site_url_host_mapping = defaultdict(set)\n",
    "    tracker_urls = set()\n",
    "    tracking_cookie_invalid_date = defaultdict(set)\n",
    "\n",
    "    if id_urls_map:\n",
    "\n",
    "        query_session = f\"\"\"SELECT js.visit_id,  js.is_session, sv.site_url\n",
    "                     FROM javascript_cookies as js LEFT JOIN site_visits as sv\n",
    "                     ON sv.visit_id = js.visit_id WHERE js.visit_id IN {format(id_urls_map)} AND js.is_session = 1;\n",
    "                     \"\"\"\n",
    "        session_df = pd.read_sql_query(query_session, db)\n",
    "        num_session_cookies = session_df[\"visit_id\"].size\n",
    "\n",
    "        # no session and domain cookies\n",
    "        query = f\"\"\"SELECT js.visit_id, js.is_http_only, \n",
    "            js.name, js.path, js.creationTime, js.expiry, js.value, js.is_session, \n",
    "            js.policy, js.host, js.is_domain, \n",
    "            js.is_secure,  js.change, sv.site_url\n",
    "                     FROM javascript_cookies as js LEFT JOIN site_visits as sv\n",
    "                     ON sv.visit_id = js.visit_id WHERE js.visit_id IN {format(id_urls_map)} AND js.is_session = 0 AND js.is_domain = 0;\n",
    "                     \"\"\"\n",
    "\n",
    "    else:\n",
    "        query_session = f\"\"\"SELECT js.visit_id,  js.is_session, sv.site_url\n",
    "                     FROM javascript_cookies as js LEFT JOIN site_visits as sv\n",
    "                     ON sv.visit_id = js.visit_id WHERE js.is_session = 1;\n",
    "                     \"\"\"\n",
    "\n",
    "        query = \"\"\"SELECT js.visit_id, js.is_http_only, \n",
    "                    js.name, js.path, js.creationTime, js.expiry, js.value, js.is_session, \n",
    "                    js.policy, js.host, js.is_domain, \n",
    "                    js.is_secure,  js.change, sv.site_url\n",
    "                             FROM javascript_cookies as js LEFT JOIN site_visits as sv\n",
    "                             ON sv.visit_id = js.visit_id  WHERE visit_id > 0 AND js.is_session = 0;\n",
    "                             \"\"\"\n",
    "\n",
    "    if max_rank is not None:\n",
    "        query += \" AND visit_id <= %i\" % max_rank\n",
    "\n",
    "    print(\"Starting get_cookie analysis\")\n",
    "    for row in tqdm(c.execute(query).fetchall()):\n",
    "        num_cookie_total += 1\n",
    "        visit_id = row[\"visit_id\"]\n",
    "        is_http_only = row[\"is_http_only\"]\n",
    "        value = row[\"value\"]\n",
    "        is_session = row[\"is_session\"]\n",
    "        is_domain = row[\"is_domain\"]\n",
    "        change = row[\"change\"]\n",
    "        site_url = row[\"site_url\"]\n",
    "        creationtime = row[\"creationTime\"]\n",
    "        expiry = row[\"expiry\"]\n",
    "        host = row[\"host\"]\n",
    "\n",
    "        if is_domain == 0:\n",
    "            # (1) the cookie has an expiration date over 90 days in the future\n",
    "            if creationtime == \"Invalid Date\" or expiry == \"Invalid Date\":\n",
    "                if site_url in tracking_cookie_invalid_date:\n",
    "                    tracking_cookie_invalid_date[site_url] = value\n",
    "                else:\n",
    "                    tracking_cookie_invalid_date[site_url].add(value)\n",
    "\n",
    "                print(\"invalid date\")\n",
    "                continue\n",
    "\n",
    "            timespan = get_delta_timespan(creationtime, expiry)\n",
    "            if timespan < 90:\n",
    "                continue\n",
    "\n",
    "            # (2) 8 ≤ length(parameter-value) ≤ 100 CHANGED\n",
    "            length = len(value)\n",
    "            if (length < 8) or (length > 150):\n",
    "                continue\n",
    "\n",
    "            # (3) the parametervalue remains the same throughout the measurement\n",
    "            if change == \"changed\" or change == \"deleted\":\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                if is_http_only == 1:\n",
    "                    num_http_cookies += 1\n",
    "\n",
    "                if timespan >= 365:\n",
    "                    num_very_long_cookie += 1\n",
    "                else:\n",
    "                    num_long_cookie += 1\n",
    "\n",
    "                num_tracking_cookies += 1\n",
    "                tracker_urls.add(site_url)\n",
    "                try:\n",
    "                    tracking_site_urls[site_url] += 1\n",
    "                except KeyError:\n",
    "                    tracking_site_urls[site_url] = 0\n",
    "                try:\n",
    "                    site_url_host_mapping[site_url].add(host)\n",
    "                except KeyError:\n",
    "                    site_url_host_mapping[site_url] = host\n",
    "\n",
    "    num_cookie_setters = len(tracker_urls)\n",
    "\n",
    "    print(\"get_cookies done, saving results\")\n",
    "    cookie_feat_dict = {\n",
    "        NUM_COOKIE_SETTERS: num_cookie_setters,\n",
    "        NUM_COOKIE_TOTAL: num_cookie_total,\n",
    "        NUM_SESSION_COOKIES: num_session_cookies,\n",
    "        NUM_TRACKING_COOKIES: num_tracking_cookies,\n",
    "        NUM_HTTP_COOKIES: num_http_cookies,\n",
    "        NUM_VERY_LONG_COOKIE: num_very_long_cookie,\n",
    "        NUM_LONG_COOKIE: num_long_cookie,\n",
    "        NUM_CRAWLED_URLS: num_crawled_urls,\n",
    "    }\n",
    "\n",
    "    tracking_sites_dict = {\n",
    "        COOKIE_SETTERS: tracker_urls,\n",
    "        TRACKING_SITE_URLS: tracking_site_urls\n",
    "    }\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"tracking_cookie_invalid_date.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(tracking_cookie_invalid_date, indent=4, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"cookie_features.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(cookie_feat_dict, indent=4, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"tracking_sites_dict.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(tracking_sites_dict, indent=4, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "\n",
    "def extract_features(db_file, out_csv, id_urls_map=defaultdict(), max_rank=None):\n",
    "    print(\"extract_features\")\n",
    "    \"\"\"Extract fingerprinting related features from the javascript table\n",
    "    of the crawl database.\n",
    "    Although we use script_url to attribute the access or the function call,\n",
    "    it may not always give the right script.\n",
    "    For instance when a script uses jquery to listen to sensor events we'll\n",
    "    attribute the (e.g. sensor related) event listening to jquery. The script\n",
    "    that uses jquery should still be in the call_stack, but not necessarily at\n",
    "    the top or bottom).\n",
    "    TODO: use call_stack to get other potential scripts.\n",
    "    The problem is how to do the attribution then, assign all access to all\n",
    "    scripts that appear in the call_stack?\"\"\"\n",
    "\n",
    "    # high level features\n",
    "    canvas_reads = defaultdict(set)\n",
    "    canvas_writes = defaultdict(set)\n",
    "    canvas_texts = defaultdict(set)\n",
    "    canvas_banned_calls = defaultdict(set)\n",
    "    canvas_styles = defaultdict(lambda: defaultdict(set))\n",
    "    battery_level_access = defaultdict(set)\n",
    "    battery_charging_time_access = defaultdict(set)\n",
    "    battery_discharging_time_access = defaultdict(set)\n",
    "    audio_ctx_calls = defaultdict(lambda: defaultdict(set))\n",
    "    webrtc_calls = defaultdict(lambda: defaultdict(set))\n",
    "    canvas_used_fonts = defaultdict(lambda: defaultdict(set))\n",
    "    canvas_measure_text_calls = defaultdict(int)\n",
    "\n",
    "    # simple features\n",
    "    script_ranks = defaultdict(set)  # site ranks where a script is embedded\n",
    "    script_features = defaultdict(set)\n",
    "\n",
    "    # To check script URLs against adblock rules\n",
    "    easylist_blocked_scripts = set()\n",
    "    easyprivacy_blocked_scripts = set()\n",
    "    disconnect_blocked_scripts = set()\n",
    "    easylist_rules, easyprivacy_rules, ublock_rules = get_adblock_rules()\n",
    "    disconnect_blocklist = get_disconnect_blocked_hosts()\n",
    "    adblock_checked_scripts = set()  # to prevent repeated lookups\n",
    "    third_party_scripts = set()\n",
    "\n",
    "    overall_script_ranks = get_script_freqs_from_db(db_file)\n",
    "\n",
    "    connection = sqlite3.connect(db_file)\n",
    "    connection.row_factory = sqlite3.Row\n",
    "    c = connection.cursor()\n",
    "\n",
    "    if id_urls_map:\n",
    "\n",
    "        query = f\"\"\"SELECT sv.site_url, sv.visit_id,\n",
    "            js.script_url, js.operation, js.arguments, js.symbol, js.value\n",
    "            FROM javascript as js LEFT JOIN site_visits as sv\n",
    "            ON sv.visit_id = js.visit_id WHERE\n",
    "            js.script_url <> '' AND js.visit_id IN {format(id_urls_map)}\n",
    "            \"\"\"\n",
    "\n",
    "    else:\n",
    "        query = \"\"\"SELECT sv.site_url, sv.visit_id,\n",
    "            js.script_url, js.operation, js.arguments, js.symbol, js.value\n",
    "            FROM javascript as js LEFT JOIN site_visits as sv\n",
    "            ON sv.visit_id = js.visit_id WHERE\n",
    "            js.script_url <> ''\n",
    "            \"\"\"\n",
    "\n",
    "    if max_rank is not None:\n",
    "        query += \" AND visit_id <= %i\" % max_rank\n",
    "\n",
    "    print(\"Starting feature extraction\")\n",
    "    for row in tqdm(c.execute(query).fetchall()):\n",
    "        visit_id = row[\"visit_id\"]\n",
    "        site_url = row[\"site_url\"]\n",
    "        script_url = row[\"script_url\"]\n",
    "        operation = row[\"operation\"]\n",
    "        arguments = row[\"arguments\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        value = row[\"value\"]\n",
    "\n",
    "        # Exclude relative URLs, data urls, blobs, javascript URLs\n",
    "        if not (script_url.startswith(\"http://\")\n",
    "                or script_url.startswith(\"https://\")):\n",
    "            continue\n",
    "\n",
    "        script_adress = get_base_script_url(script_url)\n",
    "\n",
    "        third_party_script = False\n",
    "        if is_third_party(script_url, site_url):\n",
    "            third_party_scripts.add(script_adress)\n",
    "            third_party_script = True\n",
    "\n",
    "\n",
    "\n",
    "        # get the simple feature for this call\n",
    "        feat = get_simple_feature_from_js_info(operation, arguments, symbol)\n",
    "        if feat is not None:\n",
    "            script_features[script_adress].add(feat)\n",
    "\n",
    "        script_ranks[script_adress].add(visit_id)\n",
    "\n",
    "        # Check easylist and easyprivacy blocked status\n",
    "        # if we didn't do it for this script url before\n",
    "\n",
    "        if script_url not in adblock_checked_scripts:\n",
    "\n",
    "            if easylist_rules.should_block(\n",
    "                    script_url, {'script': True,\n",
    "                                 'third-party': third_party_script}):\n",
    "                easylist_blocked_scripts.add(script_adress)\n",
    "\n",
    "            if easyprivacy_rules.should_block(\n",
    "                    script_url, {'script': True,\n",
    "                                 'third-party': third_party_script}):\n",
    "                easyprivacy_blocked_scripts.add(script_adress)\n",
    "\n",
    "            if is_blocked_by_disconnect(script_url, disconnect_blocklist):\n",
    "                disconnect_blocked_scripts.add(script_adress)\n",
    "\n",
    "        # High level features\n",
    "        # Canvas fingerprinting\n",
    "        if symbol in CANVAS_READ_FUNCS and operation == \"call\":\n",
    "            if (symbol == \"CanvasRenderingContext2D.getImageData\" and\n",
    "                    is_get_image_data_dimensions_too_small(arguments)):\n",
    "                continue\n",
    "            canvas_reads[script_adress].add(visit_id)\n",
    "        elif symbol in CANVAS_WRITE_FUNCS:\n",
    "            text = get_canvas_text(arguments)\n",
    "            # Python miscalculates the length of unicode strings that contain\n",
    "            # surrogate pairs such as emojis. This make the string look longer\n",
    "            # it really is and cause false positives.\n",
    "            # For instance \"🏴​󠁧​󠁢​󠁥​󠁮​󠁧\", which is written onto canvas by\n",
    "            # Wordpress to check emoji support, gives a length of 13.\n",
    "            # We ignore non-ascii characters to prevent these false positives.\n",
    "            if len(text.encode('ascii', 'ignore')) >= MIN_CANVAS_TEXT_LEN:\n",
    "                canvas_writes[script_adress].add(visit_id)\n",
    "                # the following is used to debug false positives\n",
    "                canvas_texts[(script_adress, visit_id)].add(text)\n",
    "        elif symbol == \"CanvasRenderingContext2D.fillStyle\" and \\\n",
    "                operation == \"call\":\n",
    "            canvas_styles[script_adress][visit_id].add(value)\n",
    "        elif operation == \"call\" and symbol in CANVAS_FP_DO_NOT_CALL_LIST:\n",
    "            canvas_banned_calls[script_adress].add(visit_id)\n",
    "        # Canvas font fingerprinting\n",
    "        elif symbol == \"CanvasRenderingContext2D.font\" and operation == \"set\":\n",
    "            canvas_used_fonts[script_adress][visit_id].add(value)\n",
    "        elif symbol == \"CanvasRenderingContext2D.measureText\" and \\\n",
    "                operation == \"call\":\n",
    "            text = json.loads(arguments)[\"0\"]\n",
    "            canvas_measure_text_calls[(script_adress, visit_id, text)] += 1\n",
    "        elif (operation == \"call\" and symbol in WEBRTC_FP_CALLS) or \\\n",
    "                (operation == \"set\" and\n",
    "                 symbol == \"RTCPeerConnection.onicecandidate\"):\n",
    "            webrtc_calls[script_adress][visit_id].add(symbol)\n",
    "\n",
    "        # Battery Status API\n",
    "        elif operation == \"get\" and symbol in \"BatteryManager.level\":\n",
    "            battery_level_access[script_adress].add(visit_id)\n",
    "        elif operation == \"get\" and symbol in BATTERY_CHARGING_TIME_CALLS:\n",
    "            battery_charging_time_access[script_adress].add(visit_id)\n",
    "        elif operation == \"get\" and symbol in BATTERY_DISCHARGING_TIME_CALLS:\n",
    "            battery_discharging_time_access[script_adress].add(visit_id)\n",
    "        elif (operation == \"call\"\n",
    "              and symbol == \"BatteryManager.addEventListener\"):\n",
    "            event_type = json.loads(arguments)[\"0\"]\n",
    "            if event_type == \"levelchange\":\n",
    "                battery_level_access[script_adress].add(visit_id)\n",
    "            elif event_type == \"chargingtimechange\":\n",
    "                battery_charging_time_access[script_adress].add(visit_id)\n",
    "            elif event_type == \"dischargingtimechange\":\n",
    "                battery_discharging_time_access[script_adress].add(visit_id)\n",
    "\n",
    "        # Audio Context API\n",
    "        elif symbol in AUDIO_CONTEXT_FUNCS:\n",
    "            audio_ctx_calls[script_adress][visit_id].add(symbol)\n",
    "\n",
    "    print(\"Feature extraction done, saving results\")\n",
    "    canvas_fingerprinters = get_canvas_fingerprinters(canvas_reads,\n",
    "                                                      canvas_writes,\n",
    "                                                      canvas_styles,\n",
    "                                                      canvas_banned_calls,\n",
    "                                                      canvas_texts)\n",
    "    canvas_font_fingerprinters = \\\n",
    "        get_canvas_font_fingerprinters(canvas_used_fonts,\n",
    "                                       canvas_measure_text_calls)\n",
    "    audio_ctx_fingerprinters = get_audio_ctx_fingerprinters(audio_ctx_calls)\n",
    "    webrtc_fingerprinters = get_webrtc_fingerprinters(webrtc_calls)\n",
    "    battery_fingerprinters = get_battery_fingerprinters(\n",
    "        battery_level_access, battery_charging_time_access,\n",
    "        battery_discharging_time_access)\n",
    "\n",
    "    request_triggering_scripts, third_party_request_triggering_scripts = \\\n",
    "        get_request_triggering_scripts(db_file)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"audio_ctx_fingerprinters\", audio_ctx_fingerprinters)\n",
    "        print(\"canvas_fingerprinters\", canvas_fingerprinters)\n",
    "        print(\"canvas_font_fingerprinters\", canvas_font_fingerprinters)\n",
    "        print(\"webrtc_fingerprinters\", webrtc_fingerprinters)\n",
    "        print(\"battery_fingerprinters\", battery_fingerprinters)\n",
    "        print(\"request_triggering_scripts\", request_triggering_scripts)\n",
    "        print(\"third_party_request_triggering_scripts\", third_party_request_triggering_scripts)\n",
    "        print(THIRD_PARTY_SCRIPT, third_party_scripts)\n",
    "        print(EASYLIST_BLOCKED, easylist_blocked_scripts)\n",
    "        print(EASYPRIVACY_BLOCKED, easyprivacy_blocked_scripts)\n",
    "        # print UBLOCK_ORIGIN_BLOCKED, ublock_blocked_scripts\n",
    "        print(DISCONNECT_BLOCKED, disconnect_blocked_scripts)\n",
    "\n",
    "    high_level_feat_dict = {\n",
    "        CANVAS_FP: canvas_fingerprinters,\n",
    "        CANVAS_FONT_FP: canvas_font_fingerprinters,\n",
    "        AUDIO_CTX_FP: audio_ctx_fingerprinters,\n",
    "        WEBRTC_FP: webrtc_fingerprinters,\n",
    "        BATTERY_FP: battery_fingerprinters,\n",
    "        TRIGGERS_REQUEST: request_triggering_scripts,\n",
    "        TRIGGERS_TP_REQUEST: third_party_request_triggering_scripts,\n",
    "        EASYLIST_BLOCKED: easylist_blocked_scripts,\n",
    "        EASYPRIVACY_BLOCKED: easyprivacy_blocked_scripts,\n",
    "        FB_COOKIEMONSTER_BLOCKED: cookiemonster_blocked_scripts,\n",
    "        # UBLOCK_ORIGIN_BLOCKED: ublock_blocked_scripts,\n",
    "        DISCONNECT_BLOCKED: disconnect_blocked_scripts,\n",
    "        THIRD_PARTY_SCRIPT: third_party_scripts\n",
    "    }\n",
    "\n",
    "    count_dict = {\n",
    "        NUM_CANVAS_FP: len(canvas_fingerprinters),\n",
    "        NUM_CANVAS_FONT_FP: len(canvas_font_fingerprinters),\n",
    "        NUM_AUDIO_CTX_FP: len(audio_ctx_fingerprinters),\n",
    "        NUM_WEBRTC_FP: len(webrtc_fingerprinters),\n",
    "        NUM_BATTERY_FP: len(battery_fingerprinters),\n",
    "        NUM_TRIGGERS_REQUEST: len(request_triggering_scripts),\n",
    "        NUM_TRIGGERS_TP_REQUEST: len(third_party_request_triggering_scripts),\n",
    "        NUM_EASYLIST_BLOCKED: len(easylist_blocked_scripts),\n",
    "        NUM_EASYPRIVACY_BLOCKED: len(easyprivacy_blocked_scripts),\n",
    "\n",
    "        # UBLOCK_ORIGIN_BLOCKED: ublock_blocked_scripts,\n",
    "        NUM_DISCONNECT_BLOCKED: len(disconnect_blocked_scripts),\n",
    "        NUM_THIRD_PARTY_SCRIPT: len(third_party_scripts)\n",
    "    }\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"count_features.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(count_dict, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"script_features.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(script_features, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"high_level_feat_dict.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(high_level_feat_dict, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"script_ranks.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(script_ranks, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    with open(join(OUT_DIR, \"%s_%s\" % (CRAWL_NAME, \"overall_script_ranks.json\")), 'w') as fp:\n",
    "        json_string = json.dumps(overall_script_ranks, cls=SetEncoder)\n",
    "        fp.write(json_string)\n",
    "\n",
    "    print(\"Finished feature extraction\")\n",
    "\n",
    "MIN_FONT_FP_FONT_COUNT = 50\n",
    "\n",
    "\n",
    "def get_script_urls_from_req_call_stack(req_call_stack):\n",
    "    \"\"\"\n",
    "    An example stack frame:\n",
    "      udm_@https://sb.scorecardresearch.com/beacon.js:1:611;null\"  # noqa\n",
    "\n",
    "    Another example, this time with eval:\n",
    "      null@http://static-alias-1.360buyimg.com/jzt/libs/behavior/v2.3/behavior.js line 1 > eval:1:619;null  # noqa\n",
    "    \"\"\"\n",
    "    script_urls = set()\n",
    "    frames = req_call_stack.split(\"\\n\")\n",
    "    for frame in frames:\n",
    "        script_url = frame. \\\n",
    "            rsplit(\":\", 2)[0]. \\\n",
    "            split(\"@\", 1)[-1]. \\\n",
    "            split(\" line\")[0]\n",
    "        if not (script_url.startswith(\"http://\")\n",
    "                or script_url.startswith(\"https://\")):\n",
    "            continue\n",
    "\n",
    "        script_url_no_param = script_url.split(\"?\")[0].split(\"&\")[0]\n",
    "        script_adress = script_url_no_param.split(\"://\")[-1]\n",
    "        script_urls.add(script_adress)\n",
    "    return script_urls\n",
    "\n",
    "\n",
    "def get_request_triggering_scripts(db_file):\n",
    "    request_triggering_scripts = set()\n",
    "    third_party_request_triggering_scripts = set()\n",
    "    connection = sqlite3.connect(db_file)\n",
    "    c = connection.cursor()\n",
    "    query = \"\"\"SELECT visit_id, url, is_third_party_channel, req_call_stack\n",
    "                   FROM http_requests\n",
    "                   WHERE req_call_stack <> ''\n",
    "                   \"\"\"\n",
    "    for row in c.execute(query):\n",
    "        _, _, is_third_party_channel, req_call_stack = row[0:4]\n",
    "        script_addrs = get_script_urls_from_req_call_stack(req_call_stack)\n",
    "        request_triggering_scripts.update(script_addrs)\n",
    "        if is_third_party_channel == 1:\n",
    "            third_party_request_triggering_scripts.update(script_addrs)\n",
    "    return request_triggering_scripts, third_party_request_triggering_scripts\n",
    "\n",
    "\n",
    "def get_battery_fingerprinters(battery_level_access,\n",
    "                               battery_charging_time_access,\n",
    "                               battery_discharging_time_access):\n",
    "    \"\"\"Find visits where all three battery related features are accessed.\n",
    "    We require scripts to access three properties:\n",
    "        battery level, charging and discharging time.\n",
    "    \"\"\"\n",
    "    battery_fingerprinters = set()\n",
    "    for script_address, visit_ids in battery_level_access.items():\n",
    "        if script_address in battery_fingerprinters:\n",
    "            continue\n",
    "        fp_visits = visit_ids. \\\n",
    "            intersection(battery_charging_time_access[script_address],\n",
    "                         battery_discharging_time_access[script_address])\n",
    "        if not fp_visits:\n",
    "            continue\n",
    "        battery_fingerprinters.add(script_address)\n",
    "        print((\"Battery fingerprinter\", script_address, \"visit#\",\n",
    "               fp_visits))\n",
    "\n",
    "    return battery_fingerprinters\n",
    "\n",
    "\n",
    "def get_canvas_font_fingerprinters(canvas_used_fonts,\n",
    "                                   canvas_measure_text_calls):\n",
    "    \"\"\"\n",
    "    From: http://randomwalker.info/publications/OpenWPM_1_million_site_tracking_measurement.pdf  # noqa\n",
    "    \"the script sets the font property to at least 50 distinct, valid values and\n",
    "    also calls the measureText method at least 50 times on the same text string.\"\n",
    "\n",
    "    \"\"\"\n",
    "    canvas_font_fingerprinters = set()\n",
    "    for script_adress, visit_id_calls_dict in canvas_used_fonts.items():\n",
    "        for font_use_visit_id, canvas_fonts in visit_id_calls_dict.items():\n",
    "            if len(canvas_fonts) < MIN_FONT_FP_FONT_COUNT:\n",
    "                continue\n",
    "            # check if there's 50+ measureText calls in this visit\n",
    "            for (script_adress, font_measure_visit_id, arguments), call_count \\\n",
    "                    in canvas_measure_text_calls.items():\n",
    "                if script_adress in canvas_font_fingerprinters:\n",
    "                    continue\n",
    "                if font_use_visit_id == font_measure_visit_id and \\\n",
    "                        call_count >= MIN_FONT_FP_FONT_COUNT:\n",
    "                    canvas_font_fingerprinters.add(script_adress)\n",
    "                    print((\"Canvas font fingerprinter:\", script_adress,\n",
    "                           \"visit#\", font_use_visit_id,\n",
    "                           arguments, len(canvas_fonts), canvas_fonts))\n",
    "                    break\n",
    "    return canvas_font_fingerprinters\n",
    "\n",
    "\n",
    "def get_webrtc_fingerprinters(webrtc_calls_dict):\n",
    "    webrtc_fingerprinters = set()\n",
    "    for script_adress, visit_id_calls_dict in webrtc_calls_dict.items():\n",
    "        if script_adress in webrtc_fingerprinters:\n",
    "            continue\n",
    "        for visit_id, webrtc_calls in visit_id_calls_dict.items():\n",
    "            # we require the script to call all 2 webrtc functions\n",
    "            # and set onicecandidate event listener\n",
    "            # +1 for set onicecandidate\n",
    "            if len(webrtc_calls) == len(WEBRTC_FP_CALLS) + 1:\n",
    "                webrtc_fingerprinters.add(script_adress)\n",
    "                # print((\"WebRTC fingerprinter:\", script_adress,\n",
    "                #      \"visit#\", visit_id))\n",
    "                break\n",
    "    return webrtc_fingerprinters\n",
    "\n",
    "\n",
    "def get_audio_ctx_fingerprinters(audio_ctx_calls_dict):\n",
    "    \"\"\"Return scripts who call the Audio Context API functions we monitor.\"\"\"\n",
    "    audio_context_fingerprinters = set()\n",
    "    for script_adress, visit_id_calls_dict in audio_ctx_calls_dict.items():\n",
    "        if script_adress in audio_context_fingerprinters:\n",
    "            continue\n",
    "        for visit_id, audio_ctx_calls in visit_id_calls_dict.items():\n",
    "            # we require the script to call all five audio context functions\n",
    "            if len(audio_ctx_calls) == len(AUDIO_CONTEXT_FUNCS):\n",
    "                audio_context_fingerprinters.add(script_adress)\n",
    "                print((\"Audio context fingerprinter:\", script_adress,\n",
    "                       \"visit#\", visit_id))\n",
    "                break\n",
    "    return audio_context_fingerprinters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MIN_CANVAS_STYLE_CALLS = 0\n",
    "\n",
    "\n",
    "def get_canvas_fingerprinters(canvas_reads, canvas_writes, canvas_styles,\n",
    "                              canvas_banned_calls, canvas_texts):\n",
    "    \"\"\"\n",
    "    We don't require text to be written to canvas with at least two color\n",
    "    as done by Englehardt and Narayanan, 2016\n",
    "    Our preliminary analysis showed that several canvas fingerprinting scripts\n",
    "    uses a single color.\n",
    "    Following are sample scripts that uses a single color:\n",
    "    https://secure.bankofamerica.com/login/sign-in/entry/cc.go?_=1498293938310\n",
    "    https://aug.americanexpress.com/collector/cc.js?v=4.4.3\n",
    "    https://deviceinfo.capitalone.com/collector/cc.js?tid=HOME_5a9c9ed4-b977-4e85-9e6e-d7ca84983d0b\n",
    "    Use the following query to find out some of the scripts we'd miss\n",
    "    if we required this condition:\n",
    "    SELECT *\n",
    "      FROM javascript\n",
    "     WHERE (symbol LIKE \"%CanvasRenderingContext2D%\" OR\n",
    "            symbol LIKE \"%HTMLCanvasElement.toDataURL%\") AND\n",
    "           id < 1000000 AND\n",
    "           (script_url LIKE \"%deviceinfo.capitalone.com%\" OR\n",
    "            script_url LIKE \"%secure.bankofamerica.com/login/sign-in/entry/cc.go%\" OR  # noqa\n",
    "            script_url LIKE \"%aug.americanexpress.com/collector/cc.js%\");\n",
    "    \"\"\"\n",
    "    canvas_fingerprinters = set()\n",
    "    for script_address, visit_ids in canvas_reads.items():\n",
    "        if script_address in canvas_fingerprinters:\n",
    "            continue\n",
    "        canvas_rw_visits = visit_ids. \\\n",
    "            intersection(canvas_writes[script_address])\n",
    "        if not canvas_rw_visits:\n",
    "            continue\n",
    "        # we can remove the following, we don't use the style/color condition\n",
    "        for canvas_rw_visit in canvas_rw_visits:\n",
    "            if len(canvas_styles[script_address][canvas_rw_visit]) < \\\n",
    "                    MIN_CANVAS_STYLE_CALLS:\n",
    "                continue\n",
    "\n",
    "            # check if the script has made a call to save, restore or\n",
    "            # addEventListener of the Canvas API. We exclude scripts making\n",
    "            # these calls to eliminate false positives\n",
    "            if canvas_rw_visit in canvas_banned_calls[script_address]:\n",
    "                print((\"Excluding potential canvas FP script\", script_address,\n",
    "                       \"visit#\", canvas_rw_visit,\n",
    "                       canvas_texts[(script_address, canvas_rw_visit)]))\n",
    "                continue\n",
    "            canvas_fingerprinters.add(script_address)\n",
    "            print((\"Canvas fingerprinter\", script_address, \"visit#\",\n",
    "                   canvas_rw_visit,\n",
    "                   canvas_texts[(script_address, canvas_rw_visit)]))\n",
    "            break\n",
    "\n",
    "    return canvas_fingerprinters\n",
    "\n",
    "\n",
    "def get_sorted_feature_list(script_features):\n",
    "    return sorted(list(reduce(set.union, list(script_features.values()))))\n",
    "\n",
    "\n",
    "def empty_file(file_handle):\n",
    "    file_handle.truncate(0)\n",
    "\n",
    "\n",
    "def filter_out_non_absolute_urls(script_features):\n",
    "    for script_url in script_features.keys():\n",
    "        print()\n",
    "        script_url, urlparse(script_url).netloc\n",
    "    return script_features\n",
    "\n",
    "\n",
    "def read_ab_rules_from_file(filename):\n",
    "    filter_list = set()\n",
    "    for l in open(filename):\n",
    "        if len(l) == 0 or l[0] == '!':  # ignore these lines\n",
    "            continue\n",
    "        else:\n",
    "            filter_list.add(l.strip())\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "def get_cookie_rules():\n",
    "    raw_cookie_rules = read_ab_rules_from_file(\"analysis_utils/fanboy-cookiemonster.txt\")\n",
    "    cookie_rules = AdblockRules(raw_cookie_rules)\n",
    "    return cookie_rules\n",
    "\n",
    "\n",
    "def get_adblock_rules():\n",
    "    raw_easylist_rules = read_ab_rules_from_file(\"analysis_utils/easylist.txt\")\n",
    "    raw_easyprivacy_rules = read_ab_rules_from_file(\"analysis_utils/easyprivacy.txt\")\n",
    "    if ENABLE_UBLOCK:\n",
    "        raw_ublock_rules = read_ab_rules_from_file(\"analysis_utils/adblock_blacklist_white.txt\")\n",
    "    else:\n",
    "        raw_ublock_rules = []\n",
    "    print((\"Loaded %s from EasyList, %s rules from EasyPrivacy\"\n",
    "           \" and %s rules from UBlockOrigin\" %\n",
    "           (len(raw_easylist_rules), len(raw_easyprivacy_rules),\n",
    "            len(raw_ublock_rules))))\n",
    "    easylist_rules = AdblockRules(raw_easylist_rules)\n",
    "    easyprivacy_rules = AdblockRules(raw_easyprivacy_rules)\n",
    "    ublock_rules = AdblockRules(raw_ublock_rules)\n",
    "\n",
    "    return easylist_rules, easyprivacy_rules, ublock_rules\n",
    "\n",
    "\n",
    "def write_feats_to_csv(script_features,\n",
    "                       sorted_feature_list,\n",
    "                       high_level_feat_dict,\n",
    "                       script_ranks,\n",
    "                       overall_script_ranks,\n",
    "                       out_csv):\n",
    "    with open(out_csv, \"a\", newline='', encoding='utf8') as f:\n",
    "\n",
    "        empty_file(f)  # start a fresh file\n",
    "        f.write(\"script_url\\t\" + \"\\t\".join(sorted_feature_list) +\n",
    "                \"\\t\" + \"\\t\".join(HIGH_LEVEL_FEATURES) + \"\\t\" + \"min_rank\" +\n",
    "                \"\\t\" + \"num_sites\" + \"\\t\" \"num_sites_overall\" + \"\\n\")\n",
    "        for script_url, script_features in script_features.items():\n",
    "\n",
    "            binary_feats = []  # binary feature vector\n",
    "            for feature in sorted_feature_list:  # iterate over sorted feats\n",
    "                if feature in script_features:  # if this script has this feat\n",
    "                    binary_feats.append(\"1\")\n",
    "                else:\n",
    "                    binary_feats.append(\"0\")\n",
    "\n",
    "            f.write(script_url + \"\\t\")  # write the script url\n",
    "            f.write(\"\\t\".join(binary_feats) + \"\\t\")  # write binary features\n",
    "\n",
    "            hi_level_feats = []  # binary hi level feature vector\n",
    "            no_rank = []\n",
    "            for hi_level_feat in HIGH_LEVEL_FEATURES:\n",
    "                if script_url in high_level_feat_dict[hi_level_feat]:\n",
    "                    hi_level_feats.append(\"1\")\n",
    "                    # print \"HIGH_LEVEL_FEATURES\", hi_level_feat, script_url\n",
    "                else:\n",
    "                    hi_level_feats.append(\"0\")\n",
    "\n",
    "            f.write(\"\\t\".join(hi_level_feats))  # write binary features\n",
    "            if not any(script_ranks[script_url]):\n",
    "                global NO_RANK\n",
    "                NO_RANK.append(script_url)\n",
    "                rank_min = None\n",
    "            else:\n",
    "                if None in script_ranks[script_url]:\n",
    "                    global CONTAINS_NONE_RANKS\n",
    "                    CONTAINS_NONE_RANKS.append(script_url)\n",
    "\n",
    "                rank_min = min(x for x in script_ranks[script_url] if x is not None and x >= 0)\n",
    "\n",
    "            f.write(\"\\t%s\\t%s\" % (rank_min, len(script_ranks[script_url])))\n",
    "\n",
    "            f.write(\"\\t%s\" % len(overall_script_ranks[script_url]) + \"\\n\")\n",
    "\n",
    "\n",
    "def write_script_visit_ids(script_visit_ids, out_csv):\n",
    "    with open(out_csv, \"a\") as f:\n",
    "        empty_file(f)  # start a fresh file\n",
    "        for script_url, visit_ids in script_visit_ids.items():\n",
    "            visit_ids_str = \",\".join(str(visit_id) for visit_id in visit_ids)\n",
    "            f.write(\"%s\\t%s\\n\" % (script_url.encode(\"utf-8\"), visit_ids_str))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Usage\n",
    "To extract features, run:\n",
    "python extract_features.py\n",
    "To extract script URL, visit_ids mapping, run:\n",
    "python extract_features.py extract_frequencies_only\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    t0 = time.time()\n",
    "    #crawl_dir = sys.argv[1]\n",
    "    crawl_dir = \"/home/marleensteinhoff/UNi/Projektseminar/Datenanalyse/data/Samples/\"\n",
    "    #OUT_DIR = sys.argv[2]\n",
    "    OUT_DIR = \"/home/marleensteinhoff/UNi/Projektseminar/Datenanalyse/data/results/\"\n",
    "    out_csv = join(OUTDIR, \"features.csv\")\n",
    "\n",
    "    crawl_dir = get_crawl_dir(crawl_dir)\n",
    "    crawl_name = basename(crawl_dir.rstrip(sep))\n",
    "    crawl_db_path = get_crawl_db_path(crawl_dir)\n",
    "    CRAWL_NAME = crawl_db_path.rsplit('/', 1)[-1].split(\".sqlite\")[0]\n",
    "    if \"extract_frequencies_only\" in sys.argv:\n",
    "        script_freqs = get_script_freqs_from_db(crawl_db_path)\n",
    "        write_script_visit_ids(script_freqs, 'script_visit_ids.csv')\n",
    "        sys.exit(0)\n",
    "    ########################################\n",
    "    LIMIT_SITE_RANK = False\n",
    "    SELECTED_IDS_ONLY = True\n",
    "    # Only to be used with the home-page only crawls\n",
    "    MAX_RANK = 0  # for debugging testing\n",
    "    if LIMIT_SITE_RANK:\n",
    "        get_cookies(crawl_db_path, MAX_RANK)\n",
    "        extract_features(crawl_db_path, out_csv, MAX_RANK)\n",
    "\n",
    "    if SELECTED_IDS_ONLY:\n",
    "        selected_ids = get_visit_id_site_url_mapping(crawl_db_path)\n",
    "        selected_visit_ids = tuple(selected_ids['visit_id'].tolist())\n",
    "\n",
    "        %prun get_cookies(crawl_db_path, selected_visit_ids)\n",
    "        %prun extract_features(crawl_db_path, out_csv, selected_visit_ids)\n",
    "\n",
    "    else:\n",
    "        get_cookies(crawl_db_path, MAX_RANK)\n",
    "        extract_features(crawl_db_path, out_csv)  # process all rows\n",
    "    ########################################\n",
    "    print((\"Feature extraction completed in\", time.time() - t0, \"seconds\"))\n",
    "    print((\"JSONs are written into: \", OUT_DIR))\n",
    "    print((\"Features are written into:\", realpath(out_csv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04aafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openwpm",
   "language": "python",
   "name": "openwpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
